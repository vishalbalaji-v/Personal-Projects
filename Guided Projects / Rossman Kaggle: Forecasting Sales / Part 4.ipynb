{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Hw2_Part4_distribute.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vishalbalaji-v/Personal-Projects/blob/main/Guided%20Projects%20/%20Rossman%20Kaggle%3A%20Forecasting%20Sales%20/%20Part%204.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EaA1H2AHyVWQ"
      },
      "source": [
        "# ML-2: Trees, Model Interrogation and Bayesian Workflow\n",
        "# Homework 2: Rossman Kaggle: Forecasting Sales\n",
        "# Part 4 : Modelling with embeddings!\n",
        "**ML-2 Cohort 1** <br>\n",
        "**Instructor: Dr. Rahul Dave**<br>\n",
        "**Max Score: 100** <br>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6jBFtovs3nh1"
      },
      "source": [
        "#importing libraries\n",
        "import numpy as np\n",
        "import scipy.stats\n",
        "import scipy.special\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.mlab as mlab\n",
        "from matplotlib import cm\n",
        "import pandas as pd\n",
        "from sklearn.pipeline import make_pipeline, make_union, Pipeline\n",
        "from sklearn.preprocessing import StandardScaler, OrdinalEncoder\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from sklearn.model_selection import ParameterGrid\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.models import Sequential\n",
        "from keras.models import Model as KerasModel\n",
        "from keras.layers import Input, Dense, Activation, Reshape\n",
        "from keras.layers import Concatenate\n",
        "from keras.layers.embeddings import Embedding\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn import linear_model\n",
        "import pickle\n",
        "import csv\n",
        "from datetime import datetime\n",
        "from sklearn import preprocessing\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "import xgboost as xgb\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hlux5Gn-n-Gz"
      },
      "source": [
        "We will repeat the first initial steps again from Part 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h5Hi8ehR7WFX"
      },
      "source": [
        "Lets import the feature_train_data.pickle file and set X,y values from the pickle file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KopW-RyZXrcG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eec4bae1-950b-466a-a9a3-ff65e6c846fd"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive',force_remount=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "arl_aj6X7VQk"
      },
      "source": [
        "f = open('/content/drive/MyDrive/Colab files/Homework 2 - ML2/feature_train_data.pickle','rb')\n",
        "(X, y) = pickle.load(f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cwMxtFTUDRFN"
      },
      "source": [
        "# we will split the train_ratio and 90% and 10% and set the train_size\n",
        "train_ratio = 0.9\n",
        "num_records = len(X)\n",
        "train_size = int(train_ratio * num_records)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XpP1Emg2Dni0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "df10122e-e35a-4664-9545-d8cea09c6266"
      },
      "source": [
        "#lets look at our data\n",
        "X[1], y[1]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([   0,    0,    0, 1058,    1,    0,    0,    1]), 4491)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X2fhYw49Dz3w"
      },
      "source": [
        "The next set of inputs is following: Write the code for this yourself\n",
        "\n",
        "1. Do you want to one hot encode the data?\n",
        "2. Do you want to provide embeddings as input - this will be set to True for models with entity embeddings\n",
        "3. Do you want to save the emmbeddings? - again set to true if you want to entity embeddings\n",
        "4. if 3 is set to true, we want to save them to a embeddings.pickle\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tqtv6VWWDuZu"
      },
      "source": [
        "#your code here\n",
        "one_hot_as_input = False \n",
        "embeddings_as_input = True #embeddings later on needs to set to true for Part 3\n",
        "save_embeddings = True\n",
        "\n",
        "saved_embeddings_fname = \"/content/drive/MyDrive/Colab files/Homework 2 - ML2/embeddings.pickle\"  # set save_embeddings to True to create this file"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ayLSo_1E0yF"
      },
      "source": [
        "## Now lets work with Models with Entity embedding!!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TTYK-isysXiu"
      },
      "source": [
        "Now that you have saved embeddings - push this into the other models as an input with X. \n",
        "\n",
        "How will we do this? \n",
        "\n",
        "We need to update our X values. \n",
        "\n",
        "1. We will define a function called embed_features, which will combine the embedding with X. \n",
        "2. Call this function and update it with the inital X values taken from the pickle file - features_train_data\n",
        "3. Then split you data, X_emb - into Xtrain and X_Val, y_train and y_val remain the same\n",
        "4. Sample the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wUVh51hgqCyp"
      },
      "source": [
        "#combining embedding\n",
        "def embed_features(X, saved_embeddings_fname):\n",
        "    f_embeddings = open(saved_embeddings_fname, \"rb\")\n",
        "    embeddings = pickle.load(f_embeddings) # loading embedding\n",
        "\n",
        "    index_embedding_mapping = {3: 0, 4: 1, 0: 2, 1: 3, 2: 4, 7: 5}\n",
        "    X_embedded = []\n",
        "\n",
        "    (num_records, num_features) = X.shape # rows and columns\n",
        "    for record in X: # each row or record\n",
        "        embedded_features = [] \n",
        "        for i, feat in enumerate(record): # index and the value of each index of the list - we have to think about the ordering\n",
        "            feat = int(feat)\n",
        "            if i not in index_embedding_mapping.keys():\n",
        "                embedded_features += [feat]\n",
        "            else:\n",
        "                embedding_index = index_embedding_mapping[i]\n",
        "                embedded_features += embeddings[embedding_index][feat].tolist()\n",
        "\n",
        "        X_embedded.append(embedded_features)\n",
        "\n",
        "    return np.array(X_embedded)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hf8U7znjHZrW"
      },
      "source": [
        "**Explain what is happening the function above**\n",
        "\n",
        "your answer here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ALCfACl0rzeK"
      },
      "source": [
        "### Embedding with X - input"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-wcLbyHps8_W"
      },
      "source": [
        "#check if embedding is needed, if yes call embed_features - with X and the embeddings passed to it - call this new X as X_emb\n",
        "if embeddings_as_input:\n",
        "  #your code here \n",
        "  X_emb = embed_features(X, saved_embeddings_fname)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MDzhYvCJHm8d"
      },
      "source": [
        "Split the train and validation based on train size and on the new X_emb values from the previous code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hLTrTSGPEaGw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4106ee43-ccdf-4ffd-9b5c-9abf9098391f"
      },
      "source": [
        "#update the X_train and X_val\n",
        "#your code here\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_emb,y, train_size=train_ratio, random_state = 42)\n",
        "print(X_train.shape, X_val.shape, y_train.shape, y_val.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(759904, 42) (84434, 42) (759904,) (84434,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "StnmulRkEnRt"
      },
      "source": [
        "def sample(X, y, n):\n",
        "    '''random samples'''\n",
        "    num_row = X.shape[0]\n",
        "    indices = np.random.randint(num_row, size=n)\n",
        "    return X[indices, :], y[indices]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ednNv14aEpjS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "97865258-a1c7-4c82-f2b5-7a0e8d18e7b1"
      },
      "source": [
        "X_train, y_train = sample(X_train, y_train, 200000)  # Simulate data sparsity\n",
        "print(\"Number of samples used for training: \" + str(y_train.shape[0]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of samples used for training: 200000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C1I6AT5MuRTH"
      },
      "source": [
        "## Add the embeddings into the Models and check their MAPE!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SmJYNA0PH5AU"
      },
      "source": [
        "All the models defined here will have the same parameters as the ones defined in Part 2!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QTRegclpugs3"
      },
      "source": [
        "#defining mape\n",
        "def MAPE(Y_actual,Y_Predicted):\n",
        "    #your code here\n",
        "    error = []\n",
        "    Y_actual = np.log(Y_actual)\n",
        "    Y_Predicted = np.log(Y_Predicted)\n",
        "    for i in range(len(Y_actual)):\n",
        "      error.append(abs((Y_actual[i] - Y_Predicted[i])/Y_actual[i]))\n",
        "    return(np.mean(error))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V4Sjp7NQu1ow"
      },
      "source": [
        "### Model 1: Random Forests"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kGX-_sRYkxPv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "204f788e-bf6d-45aa-cf8a-8a50e2970d82"
      },
      "source": [
        "#your code here\n",
        "forest = RandomForestRegressor(n_estimators=200,max_depth=35,min_samples_split=2,min_samples_leaf=1)\n",
        "forest.fit(X_train,y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
              "                      max_depth=35, max_features='auto', max_leaf_nodes=None,\n",
              "                      max_samples=None, min_impurity_decrease=0.0,\n",
              "                      min_impurity_split=None, min_samples_leaf=1,\n",
              "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
              "                      n_estimators=200, n_jobs=None, oob_score=False,\n",
              "                      random_state=None, verbose=0, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zbjdY1MnJJhV"
      },
      "source": [
        "forest_MAPE_train = MAPE(y_train,forest.predict(X_train))\n",
        "forest_MAPE_test = MAPE(y_val,forest_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RCY8mAuyMRMM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cb728d2d-02e1-4ed0-c0bb-803ed9bba53d"
      },
      "source": [
        "print('Training Mean Absolute Percentage Error is {:.4f}'.format(forest_MAPE_train))\n",
        "print('Testing Mean Absolute Percentage Error is {:.4f}'.format(forest_MAPE_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training Mean Absolute Percentage Error is 0.0032\n",
            "Testing Mean Absolute Percentage Error is 0.0100\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XYvVmYMpu_Vi"
      },
      "source": [
        "### Model 2: Boosting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m1--s_4pGOuB"
      },
      "source": [
        "#your code here\n",
        "#your code here\n",
        "feature_Xtr = xgb.DMatrix(X_train, label=y_train)\n",
        "feature_Xval = xgb.DMatrix(X_val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kel1AR7nMcRe"
      },
      "source": [
        "param_grid = {\n",
        "    'nthread': -1,\n",
        "    'max_depth': 7,\n",
        "    'eta': 0.02,\n",
        "    'silent': 1,\n",
        "    'objective': 'reg:linear',\n",
        "    'colsample_bytree': 0.7,\n",
        "    'subsample': 0.7\n",
        "}\n",
        "num_round = 3000"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LsfyG5kiMexg"
      },
      "source": [
        "xgb_fit = xgb.train(param_grid,feature_Xtr,num_round)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fmEM1V6cMhzf"
      },
      "source": [
        "xgb_pred = xgb_fit.predict(feature_Xval)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OoY31yaNMiWl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "17de7698-10e4-457d-afab-8fbe9075653e"
      },
      "source": [
        "xgb_MAPE_train = MAPE(y_train,xgb_fit.predict(feature_Xtr))\n",
        "xgb_MAPE_test = MAPE(y_val,xgb_pred)\n",
        "\n",
        "print('Training Mean Absolute Percentage Error is {:.4f}'.format(xgb_MAPE_train))\n",
        "print('Testing Mean Absolute Percentage Error is {:.4f}'.format(xgb_MAPE_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training Mean Absolute Percentage Error is 0.0068\n",
            "Testing Mean Absolute Percentage Error is 0.0081\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x5porjKMM3Yx"
      },
      "source": [
        "lst_no_embed = [0.0264, 0.02, 0.0054]\n",
        "lst_with_embed = [round(forest_MAPE_test,4), round(xgb_MAPE_test,4), '']\n",
        "df = pd.DataFrame({'MAPE': lst_no_embed, 'MAPE(with EE)': lst_with_embed}, index=['Random Forest', 'XG Boost', 'MLP'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DhM6IVJJv0rU"
      },
      "source": [
        "## Final Commments!\n",
        "\n",
        "Apart from how long this homework was, lets make some other final comments\n",
        "\n",
        "**Question 1: Did you models with Entity Embeddings perfom better?**\n",
        "\n",
        "Yes\n",
        "\n",
        "**Question 2: Now that you have completed this homework, lets answer the main purpose of the homework - How do you think entity embeddings improved the MAPE score. To show this do a similar table like the one did in Paper**\n",
        "\n",
        "Entity embeddings force the network to learn the intrinsic properties of each of the feature as well as the sales distribution in the feature space. It encodes the data in a more continuous form by mapping closely related values in an embedding space, thereby giving better predictions\n",
        "\n",
        "\n",
        "**Question 3: Add a table here to show the similar to the one done in paper - to show the different MAPE values with and without embeddings**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b-09VIvHM2N5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "ef919b5e-5415-4690-a0d4-dacb4cf0eab0"
      },
      "source": [
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>MAPE</th>\n",
              "      <th>MAPE(with EE)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Random Forest</th>\n",
              "      <td>0.0264</td>\n",
              "      <td>0.01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>XG Boost</th>\n",
              "      <td>0.0200</td>\n",
              "      <td>0.0081</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>MLP</th>\n",
              "      <td>0.0054</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 MAPE MAPE(with EE)\n",
              "Random Forest  0.0264          0.01\n",
              "XG Boost       0.0200        0.0081\n",
              "MLP            0.0054              "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    }
  ]
}